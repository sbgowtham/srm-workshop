1.Create DataFrame from CSV / text 

val df = spark.read.option("header", "false") .option("inferSchema", "true").csv("/data10")

df.show()  
df.printSchema() 


Custom column names 

val df = spark.read.option("header", "false") .option("inferSchema", "true").csv("/data10").toDF("sno", "name", "drug", "gender", "amount")


2. Read a json file ( df) 

val df = spark.read.json("/data.json")
df.show()
df.printSchema()

Input file 

{"id":1, "name":"Alice", "age":30, "salary":50000}
{"id":2, "name":"Bob", "age":25, "salary":45000}
{"id":3, "name":"Charlie", "age":35, "salary":60000}


3.Creating a DataFrame from a Manual List

import spark.implicits._

val data = Seq(
  (1, "gowtham", 30, 50000),
  (2, "kumar", 25, 45000),
  (3, "rahul", 35, 60000)
)

val df = data.toDF("id", "name", "age", "salary")
df.show()

4. Creating a DataFrame from an RDD

val rdd = sc.parallelize(Seq(
  (1, "Alice", 30, 50000),
  (2, "Bob", 25, 45000),
  (3, "Charlie", 35, 60000)
))

import spark.implicits._
val df = rdd.toDF("id", "name", "age", "salary")
df.show()


5.Creating a DataFrame with a Custom Schema

import org.apache.spark.sql.types._
import org.apache.spark.sql.Row

val schema = StructType(Array(
  StructField("id", IntegerType, true),
  StructField("name", StringType, true),
  StructField("age", IntegerType, true),
  StructField("salary", IntegerType, true)
))

val data = Seq(
  Row(1, "Alice", 30, 50000),
  Row(2, "Bob", 25, 45000),
  Row(3, "Charlie", 35, 60000)
)

val rdd = sc.parallelize(data)
val df = spark.createDataFrame(rdd, schema)

df.show()
df.printSchema()

6. Read from hive 

val df = spark.sql("SELECT * FROM my_database.my_table")
df.show()

