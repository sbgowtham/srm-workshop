
Transformation 

0.Read file 
val rdd = sc.textFile("data.txt")


1. flatMap() - Split each line into words

val wordsRdd = rdd.flatMap(line => line.split(" "))


2. map() - Convert words to key-value pairs (word, 1)

val wordPairsRdd = wordsRdd.map(word => (word, 1))

3. reduceByKey() - Count word occurrences

val wordCountRdd = wordPairsRdd.reduceByKey(_ + _)


4. filter() - Keep only words with count > 1

val filteredRdd = wordCountRdd.filter { case (_, count) => count > 1 }


5. sortBy() - Sort words by count in descending order

val sortedRdd = filteredRdd.sortBy(_._2, ascending = false)


Action 
Step 4: Collect and Display Results

sortedRdd.collect().foreach(println)


2. count() - Get the number of elements in an RDD

val count = wordCountRdd.count()
println(s"Total unique words: $count")

3. take(n) - Get the first n elements

wordCountRdd.take(3).foreach(println)


4. first() - Get the first element

val firstElement = wordCountRdd.first()
println(s"First element: $firstElement")


6. saveAsTextFile() - Save results to HDFS or local file system

wordCountRdd.saveAsTextFile("output_wordcount")



Drug data Analysis 

val rdd = sc.textFile("data.txt")

val drugAmountRdd = rdd.map(line => {
  val cols = line.split(",") 
  val drug = cols(2) // Extract drug name
  val amount = cols(3).toInt 
  (drug, amount) 
})

val drugTotalAmtRdd = drugAmountRdd.reduceByKey(_ + _)

 drugTotalAmtRdd.collect().foreach(println)



-- Get partition details 

rdd.getNumPartitions


1. Check Current Partition Count
val rdd = sc.textFile("data.txt")
println(s"Initial partitions: ${rdd.getNumPartitions}")



2. Increase or Decrease Partitions using repartition(n)

val repartitionedRdd = rdd.repartition(4) 
println(s"Partitions after repartition: ${repartitionedRdd.getNumPartitions}")



Cutsom partition 

Step 1: Create a Custom Partitioner

import org.apache.spark.Partitioner

// Custom partitioner class
class DrugPartitioner(numParts: Int) extends Partitioner {
  override def numPartitions: Int = numParts

  override def getPartition(key: Any): Int = key match {
    case "avil"        => 0
    case "metacine"    => 1
    case "paracetamol" => 2
    case _             => 3 // Default partition
  }
}


Step 2: Load Data and Apply the Custom Partitioner

// Read the data file
val rdd = sc.textFile("datagen_10.txt.txt")

// Convert to Key-Value Pair RDD (drug as key)
val kvRdd = rdd.map(line => {
  val cols = line.split(",")
  val drug = cols(2) 
  (drug, line) 
})

// Apply custom partitioning
val partitionedRdd = kvRdd.partitionBy(new DrugPartitioner(4))
